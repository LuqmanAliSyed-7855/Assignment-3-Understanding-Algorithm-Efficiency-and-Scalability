# Assignment-3-Understanding-Algorithm-Efficiency-and-Scalability

## Overview
Discusses the performance and scaling characteristics of two common options of cognitive algorithms: the Randomized Quicksort algorithm to keep data order using and the Hashing with Chaining algorithm to insert and search key-value pairs. It is concerned with the efficiency of these algorithms in different input cases and scale, in terms of big-O complexity and as experienced by a computer. Randomized Quicksort is examined in respect to its revolt against the worst-case performance by randomly selecting pivots, whereas Hashing with Chaining on its successful attempt to eliminate hash collisions. Performance is measured in the implementation, testing, and analysis to see that best-use scenarios and learn what effects the algorithmic behavior in real life.

## Instructions to Run the Code
The programs are coded in Python and are organized in three files. The first file shows an algorithm of Randomized Quicksort, which is used to sort an input list collecting a random pivot value and dividing the data recurrently. The second file contains the comparisons of Randomized Quicksort and Deterministic Quicksort in terms of the execution times of different input patterns, such as random input, sorted input, reverse sorted input, and repeated inputs of different numbers. The third file uses hash table patterned with chaining so that insert, look up, delete, and show of key-value pairs can be performed. To execute each file, start a terminal or Python context, change to the file location and call it with the Python interpreter. It does not need any additional external packages other than the standard library.

## Summary of Findings
Randomized Quicksort has the property that it performs efficiently and consistently regardless of the type of input it is given because of choice of pivot to split a particion tending towards action of produce a balanced partition. The average-case time complexity remains O(n log n), supported by both recurrence relation analysis and expected comparison counts using random variables. On the other hand, Deterministic Quicksort, which uses the first element as a pivot, suffers from significant slowdown on already sorted and reverse-sorted arrays, where partitioning becomes unbalanced, leading to O(n²) complexity in the worst case. Such a difference reveals the influence of pivot selection on the performance of quicksort.

The hash table implemented with the use of chaining is effective in handling collision since it offers a list of items to every hash position. Operations such as insert, search, and delete achieve average-case time complexity of O(1 + α), where α is the load factor, representing the ratio of stored entries to table size. The performance is also efficient when keys are uniformly distributed. As demonstrated in the analysis, a high load factor results into increased chains and poor performance, whereas a low load factor guarantees shorter chains and faster access. Clustering can be reduced by use of a hash function with fine distribution and low load factor using dynamic resize mechanism to achieve scalable performance in the retrieval processes.
